{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/Danny/Data-Mining/lab2/kaggle/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = list()\n",
    "with open(data_path + 'tweets_DM.json' , 'r') as file:\n",
    "    for line in file:\n",
    "        json_list.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = list()\n",
    "for json in json_list:\n",
    "    tweet_id = json['_source']['tweet']['tweet_id']\n",
    "    hashtags = json['_source']['tweet']['hashtags']\n",
    "    hashtag = ' '.join(hashtags)\n",
    "    text = json['_source']['tweet']['text']\n",
    "    text = text + ' ' + hashtag\n",
    "    tweet_list.append([tweet_id, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.DataFrame(tweet_list, columns=['tweet_id', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_df = pd.read_csv(data_path + 'emotion.csv')\n",
    "# emotion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "identification_df = pd.read_csv(data_path + 'data_identification.csv')\n",
    "# identification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = identification_df[identification_df['identification'] == 'test']\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = text_df.merge(emotion_df, left_on='tweet_id', right_on='tweet_id')\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = train_df['text'].to_list()\n",
    "y_list = train_df['emotion'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1455563"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list_list = list()\n",
    "for x in x_list:\n",
    "    x_list_list.append(x.split())\n",
    "len(x_list_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "931560 931560\n",
      "291113 291113\n",
      "232890 232890\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_list_list, y_list, test_size=0.2, random_state=42)\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n",
    "print(len(train_x), len(train_y))\n",
    "print(len(test_x), len(test_y))\n",
    "print(len(valid_x), len(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing text vocab dict: 100%|██████████| 931560/931560 [00:05<00:00, 166168.15it/s]\n",
      "Preparing text vocab dict: 100%|██████████| 232890/232890 [00:01<00:00, 154068.22it/s]\n",
      "2020-11-29 18:33:10,585 [DEBUG] kashgari - --- Build vocab dict finished, Total: 257059 ---\n",
      "2020-11-29 18:33:10,586 [DEBUG] kashgari - Top-10: ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '<LH>', 'the', 'to', 'I', 'a', 'and']\n",
      "Preparing classification label vocab dict: 100%|██████████| 931560/931560 [00:00<00:00, 1471960.05it/s]\n",
      "Preparing classification label vocab dict: 100%|██████████| 232890/232890 [00:00<00:00, 1385436.15it/s]\n",
      "Calculating sequence length: 100%|██████████| 931560/931560 [00:00<00:00, 1559388.46it/s]\n",
      "Calculating sequence length: 100%|██████████| 232890/232890 [00:00<00:00, 1443168.46it/s]\n",
      "2020-11-29 18:33:12,947 [DEBUG] kashgari - Calculated sequence length = 27\n",
      "2020-11-29 18:33:14,389 [DEBUG] kashgari - Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "layer_embedding (Embedding)  (None, None, 100)         25705900  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               176640    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 2056      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 25,884,596\n",
      "Trainable params: 25,884,596\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14555/14555 [==============================] - 2524s 173ms/step - loss: 1.2227 - accuracy: 0.5588 - val_loss: 1.1326 - val_accuracy: 0.5919\n",
      "Epoch 2/20\n",
      "14555/14555 [==============================] - 2553s 175ms/step - loss: 0.9169 - accuracy: 0.6739 - val_loss: 1.2362 - val_accuracy: 0.5800\n",
      "Epoch 3/20\n",
      "14555/14555 [==============================] - 2570s 177ms/step - loss: 0.6219 - accuracy: 0.7837 - val_loss: 1.5928 - val_accuracy: 0.5490\n",
      "Epoch 4/20\n",
      "14555/14555 [==============================] - 2547s 175ms/step - loss: 0.4102 - accuracy: 0.8595 - val_loss: 2.0362 - val_accuracy: 0.5310\n",
      "Epoch 5/20\n",
      "14555/14555 [==============================] - 2534s 174ms/step - loss: 0.2935 - accuracy: 0.9000 - val_loss: 2.4718 - val_accuracy: 0.5199\n",
      "Epoch 6/20\n",
      "14555/14555 [==============================] - 2427s 167ms/step - loss: 0.2288 - accuracy: 0.9218 - val_loss: 2.7493 - val_accuracy: 0.5144\n",
      "Epoch 7/20\n",
      "14555/14555 [==============================] - 2318s 159ms/step - loss: 0.1897 - accuracy: 0.9352 - val_loss: 3.0111 - val_accuracy: 0.5089\n",
      "Epoch 8/20\n",
      "14555/14555 [==============================] - 2537s 174ms/step - loss: 0.1638 - accuracy: 0.9439 - val_loss: 3.2413 - val_accuracy: 0.5109\n",
      "Epoch 9/20\n",
      "14555/14555 [==============================] - 2516s 173ms/step - loss: 0.1448 - accuracy: 0.9506 - val_loss: 3.4710 - val_accuracy: 0.5077\n",
      "Epoch 10/20\n",
      "14555/14555 [==============================] - 2479s 170ms/step - loss: 0.1319 - accuracy: 0.9546 - val_loss: 3.6406 - val_accuracy: 0.5079\n",
      "Epoch 11/20\n",
      "14555/14555 [==============================] - 2561s 176ms/step - loss: 0.1211 - accuracy: 0.9581 - val_loss: 3.7389 - val_accuracy: 0.5045\n",
      "Epoch 12/20\n",
      "14555/14555 [==============================] - 2554s 175ms/step - loss: 0.1128 - accuracy: 0.9609 - val_loss: 3.9149 - val_accuracy: 0.5038\n",
      "Epoch 13/20\n",
      "14555/14555 [==============================] - 2540s 175ms/step - loss: 0.1067 - accuracy: 0.9629 - val_loss: 4.0081 - val_accuracy: 0.5004\n",
      "Epoch 14/20\n",
      "14555/14555 [==============================] - 2550s 175ms/step - loss: 0.1004 - accuracy: 0.9651 - val_loss: 4.0903 - val_accuracy: 0.4993\n",
      "Epoch 15/20\n",
      "14555/14555 [==============================] - 2516s 173ms/step - loss: 0.0960 - accuracy: 0.9668 - val_loss: 4.1904 - val_accuracy: 0.5041\n",
      "Epoch 16/20\n",
      "14555/14555 [==============================] - 2475s 170ms/step - loss: 0.0919 - accuracy: 0.9680 - val_loss: 4.2442 - val_accuracy: 0.5031\n",
      "Epoch 17/20\n",
      "14555/14555 [==============================] - 2448s 168ms/step - loss: 0.0890 - accuracy: 0.9690 - val_loss: 4.3356 - val_accuracy: 0.5034\n",
      "Epoch 18/20\n",
      "14555/14555 [==============================] - 2452s 168ms/step - loss: 0.0862 - accuracy: 0.9699 - val_loss: 4.3650 - val_accuracy: 0.5025\n",
      "Epoch 19/20\n",
      "14555/14555 [==============================] - 2512s 173ms/step - loss: 0.0847 - accuracy: 0.9707 - val_loss: 4.4596 - val_accuracy: 0.5007\n",
      "Epoch 20/20\n",
      "14555/14555 [==============================] - 2459s 169ms/step - loss: 0.0821 - accuracy: 0.9714 - val_loss: 4.4556 - val_accuracy: 0.5016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-30 08:27:55,562 [WARNING] kashgari - Sequence length is None, will use the max length of the samples, which is 49\n",
      "2020-11-30 08:27:59,098 [DEBUG] kashgari - predict input shape (291113, 49) x: \n",
      "[[   2  935    8 ...    0    0    0]\n",
      " [   2  788   61 ...    0    0    0]\n",
      " [   2 3465   80 ...    0    0    0]\n",
      " ...\n",
      " [   2    7 1600 ...    0    0    0]\n",
      " [   2    4    9 ...    0    0    0]\n",
      " [   2 2281 6163 ...    0    0    0]]\n",
      "2020-11-30 08:28:32,940 [DEBUG] kashgari - predict output shape (291113, 8)\n",
      "2020-11-30 08:28:33,109 [DEBUG] kashgari - predict output argmax: [3 1 0 ... 2 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.3085    0.2508    0.2767      7946\n",
      "anticipation     0.5868    0.5273    0.5554     49984\n",
      "     disgust     0.3518    0.3871    0.3686     27669\n",
      "        fear     0.4495    0.4007    0.4237     12846\n",
      "         joy     0.6155    0.6261    0.6208    102943\n",
      "     sadness     0.4380    0.4384    0.4382     38745\n",
      "    surprise     0.2575    0.2760    0.2664      9816\n",
      "       trust     0.3984    0.4241    0.4108     41164\n",
      "\n",
      "    accuracy                         0.5009    291113\n",
      "   macro avg     0.4258    0.4163    0.4201    291113\n",
      "weighted avg     0.5034    0.5009    0.5016    291113\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BiGRU_Model' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cb925ef7685a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model/{}_epoch_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BiGRU_Model' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "import kashgari\n",
    "from kashgari.tasks.classification import BiGRU_Model\n",
    "kashgari.config.use_cudnn_cell = True\n",
    "import logging\n",
    "logging.basicConfig(level='DEBUG')\n",
    "\n",
    "model = BiGRU_Model()\n",
    "model.fit(train_x, \n",
    "          train_y, \n",
    "          valid_x, \n",
    "          valid_y,\n",
    "          epochs=epochs,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-30 12:21:42,712 [DEBUG] kashgari - predict input shape (291113, 49) x: \n",
      "[[   2  935    8 ...    0    0    0]\n",
      " [   2  788   61 ...    0    0    0]\n",
      " [   2 3465   80 ...    0    0    0]\n",
      " ...\n",
      " [   2    7 1600 ...    0    0    0]\n",
      " [   2    4    9 ...    0    0    0]\n",
      " [   2 2281 6163 ...    0    0    0]]\n",
      "2020-11-30 12:22:19,806 [DEBUG] kashgari - predict output shape (291113, 8)\n",
      "2020-11-30 12:22:19,967 [DEBUG] kashgari - predict output argmax: [3 1 0 ... 2 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.3085    0.2508    0.2767      7946\n",
      "anticipation     0.5868    0.5273    0.5554     49984\n",
      "     disgust     0.3518    0.3871    0.3686     27669\n",
      "        fear     0.4495    0.4007    0.4237     12846\n",
      "         joy     0.6155    0.6261    0.6208    102943\n",
      "     sadness     0.4380    0.4384    0.4382     38745\n",
      "    surprise     0.2575    0.2760    0.2664      9816\n",
      "       trust     0.3984    0.4241    0.4108     41164\n",
      "\n",
      "    accuracy                         0.5009    291113\n",
      "   macro avg     0.4258    0.4163    0.4201    291113\n",
      "weighted avg     0.5034    0.5009    0.5016    291113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-30 12:22:43,819 [INFO] kashgari - model saved to /home/Danny/Data-Mining/lab2/kaggle/kashgari/model/<kashgari.tasks.classification.bi_gru_model.BiGRU_Model object at 0x7fca3ca332e8>_epoch_20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/Danny/Data-Mining/lab2/kaggle/kashgari/model/<kashgari.tasks.classification.bi_gru_model.BiGRU_Model object at 0x7fca3ca332e8>_epoch_20'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x, test_y)\n",
    "model_path = 'model/{}_epoch_{}'.format(str(model), epochs)\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = kashgari.utils.load_model(model_path)\n",
    "# model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.merge(text_df, left_on='tweet_id', right_on='tweet_id')\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = test_df['text'].tolist()\n",
    "# text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list = model.predict(text_list)\n",
    "predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predict'] = predict_list\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = test_df[['tweet_id', 'predict']]\n",
    "output_df = output_df.rename(columns={'tweet_id':'id', 'predict':'emotion'})\n",
    "# output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'output/{}_epoch_{}.csv'.format(model.name, epochs)\n",
    "output_df.to_csv(output_path, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

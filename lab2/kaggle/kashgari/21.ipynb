{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "model_name = 'BiGRU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/Danny/Data-Mining/lab2/kaggle/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = list()\n",
    "with open(data_path + 'tweets_DM.json' , 'r') as file:\n",
    "    for line in file:\n",
    "        json_list.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = list()\n",
    "for json in json_list:\n",
    "    tweet_id = json['_source']['tweet']['tweet_id']\n",
    "    hashtags = json['_source']['tweet']['hashtags']\n",
    "    hashtag = ' '.join(hashtags)\n",
    "    text = json['_source']['tweet']['text']\n",
    "    text = text + ' ' + hashtag\n",
    "    tweet_list.append([tweet_id, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.DataFrame(tweet_list, columns=['tweet_id', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_df = pd.read_csv(data_path + 'emotion.csv')\n",
    "# emotion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "identification_df = pd.read_csv(data_path + 'data_identification.csv')\n",
    "# identification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = identification_df[identification_df['identification'] == 'test']\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = text_df.merge(emotion_df, left_on='tweet_id', right_on='tweet_id')\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = train_df['text'].to_list()\n",
    "y_list = train_df['emotion'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1455563"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list_list = list()\n",
    "for x in x_list:\n",
    "    x_list_list.append(x.split())\n",
    "len(x_list_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "931560 931560\n",
      "291113 291113\n",
      "232890 232890\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_list_list, y_list, test_size=0.2, random_state=42)\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n",
    "print(len(train_x), len(train_y))\n",
    "print(len(test_x), len(test_y))\n",
    "print(len(valid_x), len(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing text vocab dict: 100%|██████████| 931560/931560 [00:05<00:00, 170267.18it/s]\n",
      "Preparing text vocab dict: 100%|██████████| 232890/232890 [00:01<00:00, 157748.67it/s]\n",
      "2020-11-30 13:09:37,083 [DEBUG] kashgari - --- Build vocab dict finished, Total: 257059 ---\n",
      "2020-11-30 13:09:37,084 [DEBUG] kashgari - Top-10: ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '<LH>', 'the', 'to', 'I', 'a', 'and']\n",
      "Preparing classification label vocab dict: 100%|██████████| 931560/931560 [00:00<00:00, 1537063.37it/s]\n",
      "Preparing classification label vocab dict: 100%|██████████| 232890/232890 [00:00<00:00, 1448351.14it/s]\n",
      "Calculating sequence length: 100%|██████████| 931560/931560 [00:00<00:00, 1581542.19it/s]\n",
      "Calculating sequence length: 100%|██████████| 232890/232890 [00:00<00:00, 1505278.67it/s]\n",
      "2020-11-30 13:09:39,396 [DEBUG] kashgari - Calculated sequence length = 27\n",
      "2020-11-30 13:09:40,691 [DEBUG] kashgari - Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "layer_embedding (Embedding)  (None, None, 100)         25705900  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               176640    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 2056      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 25,884,596\n",
      "Trainable params: 25,884,596\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14555/14555 [==============================] - 2462s 169ms/step - loss: 1.2221 - accuracy: 0.5588 - val_loss: 1.1287 - val_accuracy: 0.5919\n",
      "Epoch 2/5\n",
      "14555/14555 [==============================] - 2533s 174ms/step - loss: 0.9187 - accuracy: 0.6726 - val_loss: 1.2239 - val_accuracy: 0.5820\n",
      "Epoch 3/5\n",
      "14555/14555 [==============================] - 2486s 171ms/step - loss: 0.6234 - accuracy: 0.7834 - val_loss: 1.5616 - val_accuracy: 0.5483\n",
      "Epoch 4/5\n",
      "14555/14555 [==============================] - 2521s 173ms/step - loss: 0.4113 - accuracy: 0.8593 - val_loss: 1.9967 - val_accuracy: 0.5339\n",
      "Epoch 5/5\n",
      "14555/14555 [==============================] - 2655s 182ms/step - loss: 0.2954 - accuracy: 0.8993 - val_loss: 2.3994 - val_accuracy: 0.5214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff17abae978>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kashgari\n",
    "from kashgari.tasks.classification import BiGRU_Model\n",
    "kashgari.config.use_cudnn_cell = True\n",
    "import logging\n",
    "logging.basicConfig(level='DEBUG')\n",
    "\n",
    "model = BiGRU_Model()\n",
    "model.fit(train_x, \n",
    "          train_y, \n",
    "          valid_x, \n",
    "          valid_y,\n",
    "          epochs=epochs,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-30 16:40:44,007 [WARNING] kashgari - Sequence length is None, will use the max length of the samples, which is 49\n",
      "2020-11-30 16:40:47,386 [DEBUG] kashgari - predict input shape (291113, 49) x: \n",
      "[[   2  935    8 ...    0    0    0]\n",
      " [   2  788   61 ...    0    0    0]\n",
      " [   2 3465   80 ...    0    0    0]\n",
      " ...\n",
      " [   2    7 1600 ...    0    0    0]\n",
      " [   2    4    9 ...    0    0    0]\n",
      " [   2 2281 6163 ...    0    0    0]]\n",
      "2020-11-30 16:41:23,641 [DEBUG] kashgari - predict output shape (291113, 8)\n",
      "2020-11-30 16:41:23,834 [DEBUG] kashgari - predict output argmax: [0 1 1 ... 2 3 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.3353    0.2557    0.2902      7946\n",
      "anticipation     0.6033    0.5496    0.5752     49984\n",
      "     disgust     0.4103    0.3514    0.3786     27669\n",
      "        fear     0.4371    0.4450    0.4410     12846\n",
      "         joy     0.6287    0.6543    0.6413    102943\n",
      "     sadness     0.4191    0.5102    0.4602     38745\n",
      "    surprise     0.2398    0.3020    0.2673      9816\n",
      "       trust     0.4602    0.4035    0.4300     41164\n",
      "\n",
      "    accuracy                         0.5209    291113\n",
      "   macro avg     0.4417    0.4340    0.4355    291113\n",
      "weighted avg     0.5223    0.5209    0.5200    291113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-30 16:41:48,052 [INFO] kashgari - model saved to /home/Danny/Data-Mining/lab2/kaggle/kashgari/model/BiGRU_epoch_5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/Danny/Data-Mining/lab2/kaggle/kashgari/model/BiGRU_epoch_5'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x, test_y)\n",
    "model_path = 'model/{}_epoch_{}'.format(model_name, epochs)\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Danny/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: The 'load_model' function is deprecated, use 'XX_Model.load_model' instead\n",
      "  \n",
      "2020-11-30 16:41:49,821 [WARNING] kashgari - Sequence length is None, will use the max length of the samples, which is 49\n",
      "2020-11-30 16:41:57,909 [DEBUG] kashgari - predict input shape (291113, 49) x: \n",
      "[[   2  935    8 ...    0    0    0]\n",
      " [   2  788   61 ...    0    0    0]\n",
      " [   2 3465   80 ...    0    0    0]\n",
      " ...\n",
      " [   2    7 1600 ...    0    0    0]\n",
      " [   2    4    9 ...    0    0    0]\n",
      " [   2 2281 6163 ...    0    0    0]]\n",
      "2020-11-30 16:42:34,437 [DEBUG] kashgari - predict output shape (291113, 8)\n",
      "2020-11-30 16:42:34,635 [DEBUG] kashgari - predict output argmax: [0 1 1 ... 2 3 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.3353    0.2557    0.2902      7946\n",
      "anticipation     0.6033    0.5496    0.5752     49984\n",
      "     disgust     0.4103    0.3514    0.3786     27669\n",
      "        fear     0.4371    0.4450    0.4410     12846\n",
      "         joy     0.6287    0.6543    0.6413    102943\n",
      "     sadness     0.4191    0.5102    0.4602     38745\n",
      "    surprise     0.2398    0.3020    0.2673      9816\n",
      "       trust     0.4602    0.4035    0.4300     41164\n",
      "\n",
      "    accuracy                         0.5209    291113\n",
      "   macro avg     0.4417    0.4340    0.4355    291113\n",
      "weighted avg     0.5223    0.5209    0.5200    291113\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'detail': {'anger': {'precision': 0.3353135313531353,\n",
       "   'recall': 0.2557261515227788,\n",
       "   'f1-score': 0.2901613594173925,\n",
       "   'support': 7946},\n",
       "  'anticipation': {'precision': 0.6033297458762547,\n",
       "   'recall': 0.5495558578745199,\n",
       "   'f1-score': 0.5751887177661679,\n",
       "   'support': 49984},\n",
       "  'disgust': {'precision': 0.4103051019116344,\n",
       "   'recall': 0.35140409844952836,\n",
       "   'f1-score': 0.3785772690106296,\n",
       "   'support': 27669},\n",
       "  'fear': {'precision': 0.4371367390639339,\n",
       "   'recall': 0.44496341273548184,\n",
       "   'f1-score': 0.4410153537535684,\n",
       "   'support': 12846},\n",
       "  'joy': {'precision': 0.6287477131015943,\n",
       "   'recall': 0.6543329803872046,\n",
       "   'f1-score': 0.6412852552659764,\n",
       "   'support': 102943},\n",
       "  'sadness': {'precision': 0.41912435068376974,\n",
       "   'recall': 0.5102077687443541,\n",
       "   'f1-score': 0.4602025375392853,\n",
       "   'support': 38745},\n",
       "  'surprise': {'precision': 0.23976702798899854,\n",
       "   'recall': 0.3019559902200489,\n",
       "   'f1-score': 0.26729191090269633,\n",
       "   'support': 9816},\n",
       "  'trust': {'precision': 0.4602127895378477,\n",
       "   'recall': 0.4035079195413468,\n",
       "   'f1-score': 0.4299989644817231,\n",
       "   'support': 41164},\n",
       "  'accuracy': 0.5209008185824748,\n",
       "  'macro avg': {'precision': 0.44174212493964604,\n",
       "   'recall': 0.4339567724344079,\n",
       "   'f1-score': 0.4354651710171799,\n",
       "   'support': 291113},\n",
       "  'weighted avg': {'precision': 0.5223103295461043,\n",
       "   'recall': 0.5209008185824748,\n",
       "   'f1-score': 0.5199581703410007,\n",
       "   'support': 291113}},\n",
       " 'precision': 0.5223103295461043,\n",
       " 'recall': 0.5209008185824748,\n",
       " 'f1-score': 0.5199581703410007,\n",
       " 'support': 291113}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'model/{}_epoch_{}'.format(model_name, epochs)\n",
    "model = kashgari.utils.load_model(model_path)\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.merge(text_df, left_on='tweet_id', right_on='tweet_id')\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = test_df['text'].tolist()\n",
    "# text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"str\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-82c83de52d76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredict_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/kashgari/tasks/classification/abc_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x_data, batch_size, truncating, multi_label_threshold, predict_kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m                                                    \u001b[0msegment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                                                    \u001b[0mseq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                                                    max_position=self.embedding.max_position)\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'predict input shape {np.array(tensor).shape} x: \\n{tensor}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/kashgari/processors/sequence_processor.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, samples, seq_length, max_position, segment)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_bos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab2idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_bos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_eos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_pad\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_pad\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": [
    "predict_list = model.predict(text_list)\n",
    "predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predict'] = predict_list\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = test_df[['tweet_id', 'predict']]\n",
    "output_df = output_df.rename(columns={'tweet_id':'id', 'predict':'emotion'})\n",
    "# output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'output/{}_epoch_{}.csv'.format(model.name, epochs)\n",
    "output_df.to_csv(output_path, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "model_name = 'bert-small'\n",
    "sequence_length = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/Danny/Data-Mining/lab2/kaggle/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = list()\n",
    "with open(data_path + 'tweets_DM.json' , 'r') as file:\n",
    "    for line in file:\n",
    "        json_list.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = list()\n",
    "for json in json_list:\n",
    "    tweet_id = json['_source']['tweet']['tweet_id']\n",
    "    hashtags = json['_source']['tweet']['hashtags']\n",
    "    hashtag = ' '.join(hashtags)\n",
    "    text = json['_source']['tweet']['text']\n",
    "#     text = text + ' ' + hashtag\n",
    "    tweet_list.append([tweet_id, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3140b1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x368b73</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x296183</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2bd6e1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2ee1dd</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455558</th>\n",
       "      <td>0x38dba0</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455559</th>\n",
       "      <td>0x300ea2</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455560</th>\n",
       "      <td>0x360b99</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455561</th>\n",
       "      <td>0x22eecf</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455562</th>\n",
       "      <td>0x2fb282</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id       emotion\n",
       "0        0x3140b1       sadness\n",
       "1        0x368b73       disgust\n",
       "2        0x296183  anticipation\n",
       "3        0x2bd6e1           joy\n",
       "4        0x2ee1dd  anticipation\n",
       "...           ...           ...\n",
       "1455558  0x38dba0           joy\n",
       "1455559  0x300ea2           joy\n",
       "1455560  0x360b99          fear\n",
       "1455561  0x22eecf           joy\n",
       "1455562  0x2fb282  anticipation\n",
       "\n",
       "[1455563 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df = pd.read_csv(data_path + 'emotion.csv')\n",
    "emotion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x29e452</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x227e25</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x293813</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x1e1a7e</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x2156a5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x2bb9d2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id identification\n",
       "0        0x28cc61           test\n",
       "1        0x29e452          train\n",
       "2        0x2b3819          train\n",
       "3        0x2db41f           test\n",
       "4        0x2a2acc          train\n",
       "...           ...            ...\n",
       "1867530  0x227e25          train\n",
       "1867531  0x293813          train\n",
       "1867532  0x1e1a7e          train\n",
       "1867533  0x2156a5          train\n",
       "1867534  0x2bb9d2          train\n",
       "\n",
       "[1867535 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identification_df = pd.read_csv(data_path + 'data_identification.csv')\n",
    "identification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dict = {\n",
    "    \"😂\": \"lolface\",\n",
    "    \"😇\": \"smile\",\n",
    "    \"😀\": \"smile\",\n",
    "    \"🎉\": \"party\",\n",
    "    \"😳\": \"embarrassed\",\n",
    "    \"😔\": \"sadface\",\n",
    "    \"👀\": \"shifty\",\n",
    "    \"🤷\": \"shrugging\",\n",
    "    \"💔\": \"brokenhearted\",\n",
    "    \"👻\": \"ghost\",\n",
    "    \"😍\": \"heart\",\n",
    "    \"🙄\": \"disdain\",\n",
    "    \"💖\": \"heart\",\n",
    "    \"✌\": \"victory\",\n",
    "    \"🎶\": \"music\",\n",
    "    \"😱\": \"shock\",\n",
    "    \"😃\": \"smile\",\n",
    "    \"😒\": \"unsatisfied\",\n",
    "    \"👊\": \"brofist\",\n",
    "    \"😄\": \"smile\",\n",
    "    \"🌞\": \"smile\",\n",
    "    \"🙌\": \"celebration\",\n",
    "    \"😁\": \"smile\",\n",
    "    \"🤗\": \"hugging\",\n",
    "    \"🤣\": \"rofl\",\n",
    "    \"🌈\": \"gaypride\",\n",
    "    \"😉\": \"winking\",\n",
    "    \"💞\": \"heart\",\n",
    "    \"🙃\": \"irony\",\n",
    "    \"😜\": \"winking\",\n",
    "    \"😭\": \"bawling\",\n",
    "    \"🤔\": \"thinker\",\n",
    "    \"😎\": \"cool\",\n",
    "    \"💛\": \"heart\",\n",
    "    \"💚\": \"heart\",\n",
    "    \"💃\": \"fun\",\n",
    "    \"💗\": \"heart\",\n",
    "    \"😬\": \"awkward\",\n",
    "    \"😌\": \"relieved\",\n",
    "    \"😅\": \"whew\",\n",
    "    \"💋\": \"kiss\",\n",
    "    \"🙈\": \"laugh\",\n",
    "    \"😊\": \"^^\",\n",
    "    \"👌\": \"okay\",\n",
    "    \"😡\": \"angry\",\n",
    "    \"😘\": \"kiss\",\n",
    "    \"😩\": \"weary\",\n",
    "    \"🔥\": \"excellent\",\n",
    "    \"💙\": \"heart\",\n",
    "    \"💕\": \"heart\",\n",
    "    \"👏\": \"clapping\",\n",
    "    \"👍\": \"thumbsup\",\n",
    "    \"💯\": \"perfect\",\n",
    "    \"💜\": \"heart\",\n",
    "    \"🕘\" : \"late\",\n",
    "    \"😡\" : \"angry\",\n",
    "    \"😒\" : \"dissatisfied\",\n",
    "    \"😤\" : \"angry\",\n",
    "    \"😠\" : \"angry\",\n",
    "    \"😑\" : \"annoy\",\n",
    "    \"😰\": \"anxious\",\n",
    "    \"😯\": \"surprise\",\n",
    "    \"😨\": \"scared\",\n",
    "    \"😲\": \"astonished\",\n",
    "    \"💪\": \"strong\",\n",
    "    \"🤦\": \"facepalm\",\n",
    "    \"✨\": \"sparkle\",\n",
    "    \"😢\": \"crying\",\n",
    "    \"💓\": \"heart\",\n",
    "    \"👑\": \"crown\",\n",
    "    \"🤘\": \"rockon\",\n",
    "    \"🌹\": \"rose\",\n",
    "    \"😋\": \"delicious\",\n",
    "    \"😏\": \"flirting\",\n",
    "    \"😆\": \"XD\",\n",
    "    \"😫\": \"exhausted\",\n",
    "    \"😦\": \"frowning\",\n",
    "    \"🙏\": \"please\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_name_dict = {\n",
    "    \"#realdonaldtrump\": \"sadness\",\n",
    "    \"#fifthharmony\": \"sadness\",\n",
    "    \"#mostrequestlive\": \"sadness\",\n",
    "    \"#onairromeo\": \"sadness\",\n",
    "    \"#matthardybrand\": \"sadness\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id                                               text\n",
       "0        0x376b20  People who post \"add me on #Snapchat\" must be ...\n",
       "1        0x2d5350  @brianklaas As we see, Trump is dangerous to #...\n",
       "2        0x28b412  Confident of your obedience, I write to you, k...\n",
       "3        0x1cd5b0                Now ISSA is stalking Tasha 😂😂😂 <LH>\n",
       "4        0x2de201  \"Trust is not the same as faith. A friend is s...\n",
       "...           ...                                                ...\n",
       "1867530  0x316b80  When you buy the last 2 tickets remaining for ...\n",
       "1867531  0x29d0cb  I swear all this hard work gone pay off one da...\n",
       "1867532  0x2a6a4f  @Parcel2Go no card left when I wasn't in so I ...\n",
       "1867533  0x24faed  Ah, corporate life, where you can date <LH> us...\n",
       "1867534  0x34be8c             Blessed to be living #Sundayvibes <LH>\n",
       "\n",
       "[1867535 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.DataFrame(tweet_list, columns=['tweet_id', 'text'])\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def replace_word(text):\n",
    "    text_list = text.split()\n",
    "    for i, j in enumerate(text_list):\n",
    "        if j in emoji_dict:\n",
    "            text_list[i] = emoji_dict[j]\n",
    "        if j in frequent_name_dict:\n",
    "            text_list[i] = frequent_name_dict[j]\n",
    "    text = ' '.join(text_list)\n",
    "    text = re.sub('<lh>|<|>|@|#|', '', text)\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 27s, sys: 8.67 s, total: 2min 35s\n",
      "Wall time: 2min 36s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>[people, who, post, \", add, me, on, snapchat, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>[as, we, see, ,, trump, is, dangerous, to, fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>[confident, of, your, obedience, ,, i, write, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>[now, issa, is, stalking, tasha, lolface, lolf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>[\", trust, is, not, the, same, as, faith, ., a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>[when, you, buy, the, last, 2, tickets, remain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>[i, swear, all, this, hard, work, gone, pay, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>[no, card, left, when, i, wasn't, in, so, i, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>[ah, ,, corporate, life, ,, where, you, can, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "      <td>[blessed, to, be, living, sundayvibes]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id                                               text  \\\n",
       "0        0x376b20  People who post \"add me on #Snapchat\" must be ...   \n",
       "1        0x2d5350  @brianklaas As we see, Trump is dangerous to #...   \n",
       "2        0x28b412  Confident of your obedience, I write to you, k...   \n",
       "3        0x1cd5b0                Now ISSA is stalking Tasha 😂😂😂 <LH>   \n",
       "4        0x2de201  \"Trust is not the same as faith. A friend is s...   \n",
       "...           ...                                                ...   \n",
       "1867530  0x316b80  When you buy the last 2 tickets remaining for ...   \n",
       "1867531  0x29d0cb  I swear all this hard work gone pay off one da...   \n",
       "1867532  0x2a6a4f  @Parcel2Go no card left when I wasn't in so I ...   \n",
       "1867533  0x24faed  Ah, corporate life, where you can date <LH> us...   \n",
       "1867534  0x34be8c             Blessed to be living #Sundayvibes <LH>   \n",
       "\n",
       "                                                     token  \n",
       "0        [people, who, post, \", add, me, on, snapchat, ...  \n",
       "1        [as, we, see, ,, trump, is, dangerous, to, fre...  \n",
       "2        [confident, of, your, obedience, ,, i, write, ...  \n",
       "3        [now, issa, is, stalking, tasha, lolface, lolf...  \n",
       "4        [\", trust, is, not, the, same, as, faith, ., a...  \n",
       "...                                                    ...  \n",
       "1867530  [when, you, buy, the, last, 2, tickets, remain...  \n",
       "1867531  [i, swear, all, this, hard, work, gone, pay, o...  \n",
       "1867532  [no, card, left, when, i, wasn't, in, so, i, h...  \n",
       "1867533  [ah, ,, corporate, life, ,, where, you, can, d...  \n",
       "1867534             [blessed, to, be, living, sundayvibes]  \n",
       "\n",
       "[1867535 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "text_df['token'] = text_df['text'].apply(lambda s : s.lower())\n",
    "text_df['token'] = text_df['token'].apply(lambda s : tweet_tokenizer.tokenize(s))\n",
    "text_df['token'] = text_df['token'].apply(lambda s : ' '.join(s))\n",
    "text_df['token'] = text_df['token'].apply(lambda s : replace_word(s))\n",
    "\n",
    "# text_df['token'] = text_df['text'].apply(lambda s : s.split())\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = identification_df[identification_df['identification'] == 'test']\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = text_df.merge(emotion_df, left_on='tweet_id', right_on='tweet_id')\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1455563\n",
      "1455563\n"
     ]
    }
   ],
   "source": [
    "x_list = train_df['token'].to_list()\n",
    "y_list = train_df['emotion'].to_list()\n",
    "print(len(x_list))\n",
    "print(len(y_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "931560 931560\n",
      "291113 291113\n",
      "232890 232890\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_list, y_list, test_size=0.2, random_state=42)\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n",
    "print(len(train_x), len(train_y))\n",
    "print(len(test_x), len(test_y))\n",
    "print(len(valid_x), len(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-02 18:39:17,942 [DEBUG] kashgari - ------------------------------------------------\n",
      "2020-12-02 18:39:17,943 [DEBUG] kashgari - Loaded transformer model's vocab\n",
      "2020-12-02 18:39:17,943 [DEBUG] kashgari - config_path       : /home/Danny/pretrain_model/bert-small/bert_config.json\n",
      "2020-12-02 18:39:17,944 [DEBUG] kashgari - vocab_path      : /home/Danny/pretrain_model/bert-small/vocab.txt\n",
      "2020-12-02 18:39:17,944 [DEBUG] kashgari - checkpoint_path : /home/Danny/pretrain_model/bert-small/bert_model.ckpt\n",
      "2020-12-02 18:39:17,944 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused0]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]']\n",
      "2020-12-02 18:39:17,945 [DEBUG] kashgari - ------------------------------------------------\n",
      "Preparing text vocab dict: 100%|██████████| 931560/931560 [00:03<00:00, 238856.92it/s]\n",
      "Preparing text vocab dict: 100%|██████████| 232890/232890 [00:00<00:00, 233619.94it/s]\n",
      "2020-12-02 18:39:23,379 [DEBUG] kashgari - --- Build vocab dict finished, Total: 97676 ---\n",
      "2020-12-02 18:39:23,380 [DEBUG] kashgari - Top-10: ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '.', 'the', '!', 'to', ',', 'i']\n",
      "Preparing classification label vocab dict: 100%|██████████| 931560/931560 [00:00<00:00, 1856832.73it/s]\n",
      "Preparing classification label vocab dict: 100%|██████████| 232890/232890 [00:00<00:00, 1841501.27it/s]\n",
      "2020-12-02 18:39:26,278 [DEBUG] kashgari - Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (Embedding)     (None, None, 512)    15627264    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, None, 512)    1024        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, None, 512)    0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, None, 512)    262144      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, None, 512)    1024        Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, None, 512)    0           Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 512)    1050624     Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 512)    0           Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 512)    0           Embedding-Dropout[0][0]          \n",
      "                                                                 Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 512)    1024        Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward (Feed (None, None, 512)    2099712     Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Dropo (None, None, 512)    0           Transformer-0-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Add ( (None, None, 512)    0           Transformer-0-MultiHeadSelfAttent\n",
      "                                                                 Transformer-0-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Norm  (None, None, 512)    1024        Transformer-0-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 512)    1050624     Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 512)    0           Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 512)    0           Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 512)    1024        Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward (Feed (None, None, 512)    2099712     Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Dropo (None, None, 512)    0           Transformer-1-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Add ( (None, None, 512)    0           Transformer-1-MultiHeadSelfAttent\n",
      "                                                                 Transformer-1-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Norm  (None, None, 512)    1024        Transformer-1-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 512)    1050624     Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 512)    0           Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 512)    0           Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 512)    1024        Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward (Feed (None, None, 512)    2099712     Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Dropo (None, None, 512)    0           Transformer-2-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Add ( (None, None, 512)    0           Transformer-2-MultiHeadSelfAttent\n",
      "                                                                 Transformer-2-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Norm  (None, None, 512)    1024        Transformer-2-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 512)    1050624     Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 512)    0           Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 512)    0           Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 512)    1024        Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward (Feed (None, None, 512)    2099712     Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Dropo (None, None, 512)    0           Transformer-3-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Add ( (None, None, 512)    0           Transformer-3-MultiHeadSelfAttent\n",
      "                                                                 Transformer-3-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Norm  (None, None, 512)    1024        Transformer-3-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 256)          656384      Transformer-3-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 8)            2056        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 8)            0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 29,159,432\n",
      "Trainable params: 658,440\n",
      "Non-trainable params: 28,500,992\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14555/14555 [==============================] - 627s 43ms/step - loss: 1.3866 - accuracy: 0.4941 - val_loss: 1.3146 - val_accuracy: 0.5242\n",
      "Epoch 2/50\n",
      "14555/14555 [==============================] - 525s 36ms/step - loss: 1.3130 - accuracy: 0.5235 - val_loss: 1.2836 - val_accuracy: 0.5357\n",
      "Epoch 3/50\n",
      "14555/14555 [==============================] - 525s 36ms/step - loss: 1.2894 - accuracy: 0.5326 - val_loss: 1.2751 - val_accuracy: 0.5390\n",
      "Epoch 4/50\n",
      "14555/14555 [==============================] - 525s 36ms/step - loss: 1.2750 - accuracy: 0.5380 - val_loss: 1.2693 - val_accuracy: 0.5412\n",
      "Epoch 5/50\n",
      "14555/14555 [==============================] - 525s 36ms/step - loss: 1.2660 - accuracy: 0.5413 - val_loss: 1.2654 - val_accuracy: 0.5430\n",
      "Epoch 6/50\n",
      "14555/14555 [==============================] - 525s 36ms/step - loss: 1.2586 - accuracy: 0.5439 - val_loss: 1.2635 - val_accuracy: 0.5437\n",
      "Epoch 7/50\n",
      "14555/14555 [==============================] - 525s 36ms/step - loss: 1.2527 - accuracy: 0.5464 - val_loss: 1.2619 - val_accuracy: 0.5457\n",
      "Epoch 8/50\n",
      "14555/14555 [==============================] - 525s 36ms/step - loss: 1.2481 - accuracy: 0.5477 - val_loss: 1.2603 - val_accuracy: 0.5458\n",
      "Epoch 9/50\n",
      "14555/14555 [==============================] - 1228s 84ms/step - loss: 1.2448 - accuracy: 0.5495 - val_loss: 1.2617 - val_accuracy: 0.5448\n",
      "Epoch 10/50\n",
      "14555/14555 [==============================] - 1235s 85ms/step - loss: 1.2416 - accuracy: 0.5505 - val_loss: 1.2582 - val_accuracy: 0.5468\n",
      "Epoch 11/50\n",
      "14555/14555 [==============================] - 1234s 85ms/step - loss: 1.2385 - accuracy: 0.5520 - val_loss: 1.2557 - val_accuracy: 0.5472\n",
      "Epoch 12/50\n",
      "14555/14555 [==============================] - 1239s 85ms/step - loss: 1.2361 - accuracy: 0.5526 - val_loss: 1.2573 - val_accuracy: 0.5475\n",
      "Epoch 13/50\n",
      "14555/14555 [==============================] - 927s 64ms/step - loss: 1.2332 - accuracy: 0.5540 - val_loss: 1.2577 - val_accuracy: 0.5464\n",
      "Epoch 14/50\n",
      "14555/14555 [==============================] - 1233s 85ms/step - loss: 1.2315 - accuracy: 0.5544 - val_loss: 1.2552 - val_accuracy: 0.5486\n",
      "Epoch 15/50\n",
      "14555/14555 [==============================] - 1231s 85ms/step - loss: 1.2294 - accuracy: 0.5545 - val_loss: 1.2559 - val_accuracy: 0.5477\n",
      "Epoch 16/50\n",
      "14555/14555 [==============================] - 1230s 84ms/step - loss: 1.2281 - accuracy: 0.5552 - val_loss: 1.2553 - val_accuracy: 0.5479\n",
      "Epoch 17/50\n",
      "14555/14555 [==============================] - 1235s 85ms/step - loss: 1.2260 - accuracy: 0.5565 - val_loss: 1.2529 - val_accuracy: 0.5495\n",
      "Epoch 18/50\n",
      "14555/14555 [==============================] - 1235s 85ms/step - loss: 1.2250 - accuracy: 0.5568 - val_loss: 1.2541 - val_accuracy: 0.5491\n",
      "Epoch 19/50\n",
      "14555/14555 [==============================] - 1247s 86ms/step - loss: 1.2239 - accuracy: 0.5574 - val_loss: 1.2561 - val_accuracy: 0.5488\n",
      "Epoch 20/50\n",
      "14555/14555 [==============================] - 1242s 85ms/step - loss: 1.2232 - accuracy: 0.5572 - val_loss: 1.2553 - val_accuracy: 0.5490\n",
      "Epoch 21/50\n",
      "14555/14555 [==============================] - 1244s 85ms/step - loss: 1.2220 - accuracy: 0.5577 - val_loss: 1.2539 - val_accuracy: 0.5489\n",
      "Epoch 22/50\n",
      "14555/14555 [==============================] - 1244s 85ms/step - loss: 1.2209 - accuracy: 0.5581 - val_loss: 1.2551 - val_accuracy: 0.5477\n",
      "Epoch 23/50\n",
      " 8076/14555 [===============>..............] - ETA: 7:37 - loss: 1.2198 - accuracy: 0.5585"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import kashgari\n",
    "from kashgari.tasks.classification import BiLSTM_Model\n",
    "kashgari.config.use_cudnn_cell = True\n",
    "import logging\n",
    "logging.basicConfig(level='DEBUG')\n",
    "from kashgari.embeddings import BertEmbedding\n",
    "bert_embed = BertEmbedding('/home/Danny/pretrain_model/{}'.format(model_name))\n",
    "model = BiLSTM_Model(bert_embed, sequence_length=sequence_length)\n",
    "history = model.fit(train_x, \n",
    "                    train_y, \n",
    "                    valid_x, \n",
    "                    valid_y,\n",
    "                    epochs=epochs,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_x, test_y)\n",
    "model_path = 'model/{}_epoch_{}'.format(model_name, epochs)\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy', 'val_accuracy', 'loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = 'model/{}_epoch_{}'.format(model_name, epochs)\n",
    "# model = kashgari.utils.load_model(model_path)\n",
    "# model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.merge(text_df, left_on='tweet_id', right_on='tweet_id')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = test_df['token'].tolist()\n",
    "text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list = model.predict(text_list)\n",
    "predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predict'] = predict_list\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = test_df[['tweet_id', 'predict']]\n",
    "output_df = output_df.rename(columns={'tweet_id':'id', 'predict':'emotion'})\n",
    "# output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'output/{}_epoch_{}.csv'.format(model_name, epochs)\n",
    "output_df.to_csv(output_path, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
